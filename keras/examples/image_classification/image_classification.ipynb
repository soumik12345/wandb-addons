{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using Keras\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/soumik12345/wandb-addons/blob/main/docs/keras/examples/image_classififcation.ipynb)\n",
    "\n",
    "This notebook demonstrates how to perform transfer-learning using a pre-trained model from Keras Applications and perform experiment tracking using Weights & Biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q namex\n",
    "!apt install python3.10-venv\n",
    "!git clone https://github.com/keras-team/keras-core.git && cd keras-core\n",
    "!python pip_build.py --install\n",
    "!pip install -q git+https://github.com/keras-team/keras-cv\n",
    "!pip install --upgrade -q git+https://github.com/soumik12345/wandb-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# works with tensorflow, jax and torch backends\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.image as tf_image\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import keras as keras\n",
    "from keras import ops\n",
    "from keras import layers\n",
    "from keras import applications\n",
    "\n",
    "import wandb\n",
    "from wandb_addons.keras import WandbMetricsLogger\n",
    "from wandb_addons.keras import WandbModelCheckpoint\n",
    "from wandb_addons.keras import WandBImageClassificationCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a Weights & Biases run and Set up the Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"keras-community-days\", job_type=\"classification\")\n",
    "\n",
    "config = wandb.config\n",
    "config.batch_size = 64\n",
    "config.dataset_name = \"stanford_dogs\"\n",
    "config.image_size = 224\n",
    "config.epochs = 10\n",
    "config.top_dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dataset Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_dataset, test_dataset), info = tfds.load(\n",
    "    config.dataset_name,\n",
    "    split=[\"train\", \"test\"],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "train_dataset = train_dataset.take(100)\n",
    "test_dataset = test_dataset.take(100)\n",
    "config.classes = [name.split(\"-\")[-1] for name in info.features[\"label\"].names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    lambda image, label: (\n",
    "        tf_image.resize(image, (config.image_size, config.image_size)), label\n",
    "    )\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda image, label: (\n",
    "        tf_image.resize(image, (config.image_size, config.image_size)), label\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_preprocess(image, label):\n",
    "    label = tf.one_hot(label, len(config.classes))\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    input_preprocess, num_parallel_calls=tf_data.AUTOTUNE\n",
    ")\n",
    "train_dataset = train_dataset.batch(\n",
    "    batch_size=config.batch_size, drop_remainder=True\n",
    ")\n",
    "train_dataset = train_dataset.prefetch(tf_data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    input_preprocess, num_parallel_calls=tf_data.AUTOTUNE\n",
    ")\n",
    "test_dataset = test_dataset.batch(\n",
    "    batch_size=config.batch_size, drop_remainder=True\n",
    ")\n",
    "test_dataset = test_dataset.prefetch(tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(config.image_size, config.image_size, 3))\n",
    "x = inputs\n",
    "model = applications.EfficientNetB0(\n",
    "    include_top=False, input_tensor=x, weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "# Freeze the pretrained weights\n",
    "model.trainable = False\n",
    "\n",
    "# Rebuild top\n",
    "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Dropout(config.top_dropout_rate, name=\"top_dropout\")(x)\n",
    "outputs = layers.Dense(len(config.classes), activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "# Compile\n",
    "model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # Log your metrics as you train\n",
    "    WandbMetricsLogger(log_freq=\"batch\"),\n",
    "    # Save and version your model checkpoints\n",
    "    WandbModelCheckpoint(\"model.keras\"),\n",
    "    # Visualize your model's performance\n",
    "    WandBImageClassificationCallback(\n",
    "        dataset=test_dataset,\n",
    "        class_labels=config.classes,\n",
    "        max_items_for_visualization=50,\n",
    "    )\n",
    "]\n",
    "\n",
    "# Start training...\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=config.epochs,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Finish the experiment\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
