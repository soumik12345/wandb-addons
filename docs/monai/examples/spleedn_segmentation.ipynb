{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 23:28:19.949045: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 23:28:22.055735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import wandb\n",
    "from wandb_addons.monai import (\n",
    "    WandbStatsHandler,\n",
    "    WandBImageHandler,\n",
    "    WandbModelCheckpointSaver\n",
    ")\n",
    "\n",
    "import ignite\n",
    "from ignite.engine import Events\n",
    "from ignite.handlers import global_step_from_engine, Checkpoint\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from monai.handlers import (\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,\n",
    ")\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Resize,\n",
    ")\n",
    "from monai.data import (\n",
    "    ArrayDataset,\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    decollate_batch,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.apps import download_and_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgeekyrakshit\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb-addons/wandb/run-20230420_232832-0re2ts61</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/geekyrakshit/monai-integration/runs/0re2ts61' target=\"_blank\">true-dust-72</a></strong> to <a href='https://wandb.ai/geekyrakshit/monai-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/geekyrakshit/monai-integration' target=\"_blank\">https://wandb.ai/geekyrakshit/monai-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/geekyrakshit/monai-integration/runs/0re2ts61' target=\"_blank\">https://wandb.ai/geekyrakshit/monai-integration/runs/0re2ts61</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/geekyrakshit/monai-integration/runs/0re2ts61?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4757cb5f40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the environment variable\n",
    "os.environ[\"MONAI_DATA_DIRECTORY\"] = \"./output\"\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "wandb.init(project=\"monai-integration\", save_code=True, sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the link of the dataset\n",
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "# define the hash value to validate the downloaded file\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "# define the path for downloading the .tar file\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "# define the directory for extracting the contents of the .tar file\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "if not os.path.exists(data_dir):\n",
    "    # download, extract and validate the file\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
    "\n",
    "\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-57, a_max=164,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-57, a_max=164,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\")\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # data\n",
    "    \"cache_rate\": 1.0,\n",
    "    \"num_workers\": 2,\n",
    "\n",
    "\n",
    "    # train settings\n",
    "    \"train_batch_size\": 2,\n",
    "    \"val_batch_size\": 1,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"max_epochs\": 100,\n",
    "    \"val_interval\": 10, # check validation score after n epochs\n",
    "    \"lr_scheduler\": \"cosine_decay\", # just to keep track\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Unet model (you can even use nested dictionary and this will be handled by W&B automatically)\n",
    "    \"model_type\": \"unet\", # just to keep track\n",
    "    \"model_params\": dict(spatial_dims=3,\n",
    "                  in_channels=1,\n",
    "                  out_channels=2,\n",
    "                  channels=(16, 32, 64, 128, 256),\n",
    "                  strides=(2, 2, 2, 2),\n",
    "                  num_res_units=2,\n",
    "                  norm=Norm.BATCH,\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 32/32 [02:16<00:00,  4.27s/it]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:31<00:00,  3.49s/it]\n"
     ]
    }
   ],
   "source": [
    "def train_collate_fn(data):\n",
    "    images, labels = [], []\n",
    "    for idx in range(len(data)):\n",
    "        for d_idx in range(len(data[idx])):\n",
    "            images.append(data[idx][d_idx][\"image\"])\n",
    "            labels.append(data[idx][d_idx][\"label\"])\n",
    "    return torch.stack(images).float(), torch.stack(labels).float()\n",
    "\n",
    "\n",
    "def val_collate_fn(data):\n",
    "    images, labels = [], []\n",
    "    for idx in range(len(data)):\n",
    "        images.append(data[idx][\"image\"])\n",
    "        labels.append(data[idx][\"label\"])\n",
    "    return torch.stack(images).float(), torch.stack(labels).float()\n",
    "\n",
    "\n",
    "train_ds = CacheDataset(\n",
    "    data=train_files,\n",
    "    transform=train_transforms,\n",
    "    cache_rate=config['cache_rate'],\n",
    "    num_workers=config['num_workers']\n",
    ")\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config['train_batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    collate_fn=train_collate_fn\n",
    ")\n",
    "\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files,\n",
    "    transform=val_transforms,\n",
    "    cache_rate=config['cache_rate'],\n",
    "    num_workers=config['num_workers']\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=config['val_batch_size'],\n",
    "    num_workers=config['num_workers'],\n",
    "    collate_fn=val_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(**config['model_params']).to(device)\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=config['max_epochs'], eta_min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ignite.engine.create_supervised_trainer(model, optimizer, loss_function, device, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 23:32:26.638112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# optional section for checkpoint and tensorboard logging\n",
    "# adding checkpoint handler to save models (network\n",
    "# params and optimizer stats) during training\n",
    "log_dir = os.path.join(root_dir, \"logs\")\n",
    "\n",
    "# StatsHandler prints loss at every iteration\n",
    "# user can also customize print functions and\n",
    "# can use output_transform to convert\n",
    "# engine.state.output if it's not a loss value\n",
    "train_stats_handler = StatsHandler(\n",
    "    name=\"trainer\", output_transform=lambda x: x\n",
    ")\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "# TensorBoardStatsHandler plots loss at every iteration\n",
    "train_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    log_dir=log_dir, output_transform=lambda x: x\n",
    ")\n",
    "train_tensorboard_stats_handler.attach(trainer)\n",
    "\n",
    "# WandbStatsHandler plots loss at every iteration\n",
    "train_wandb_stats_handler = WandbStatsHandler(output_transform=lambda x: x)\n",
    "train_wandb_stats_handler.attach(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7f47543bd5e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional section for model validation during training\n",
    "validation_every_n_epochs = 1\n",
    "# Set parameters for validation\n",
    "metric_name = \"Mean_Dice\"\n",
    "# add evaluation metric to the evaluator engine\n",
    "val_metrics = {metric_name: MeanDice()}\n",
    "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_label = Compose([AsDiscrete(threshold=0.5)])\n",
    "# Ignite evaluator expects batch=(img, seg) and\n",
    "# returns output=(y_pred, y) at every iteration,\n",
    "# user can add output_transform to return other values\n",
    "evaluator = ignite.engine.create_supervised_evaluator(\n",
    "    model,\n",
    "    val_metrics,\n",
    "    device,\n",
    "    True,\n",
    "    output_transform=lambda x, y, y_pred: (\n",
    "        [post_pred(i) for i in decollate_batch(y_pred)],\n",
    "        [post_label(i) for i in decollate_batch(y)],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# create a validation data loader\n",
    "val_imtrans = Compose([Resize((96, 96, 96))])\n",
    "val_segtrans = Compose([Resize((96, 96, 96))])\n",
    "val_images = [data[\"image\"] for data in val_ds[:20]]\n",
    "val_labels = [data[\"label\"] for data in val_ds[:20]]\n",
    "val_ds = ArrayDataset(val_images, val_imtrans, val_images, val_segtrans)\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=5, num_workers=8, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "@trainer.on(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED(\n",
    "        every=validation_every_n_epochs\n",
    "    )\n",
    ")\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "\n",
    "# Add stats event handler to print validation stats via evaluator\n",
    "val_stats_handler = StatsHandler(\n",
    "    name=\"evaluator\",\n",
    "    # no need to print loss value, so disable per iteration output\n",
    "    output_transform=lambda x: None,\n",
    "    # fetch global epoch number from trainer\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to record metrics to TensorBoard at every validation epoch\n",
    "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    log_dir=log_dir,\n",
    "    # no need to plot loss value, so disable per iteration output\n",
    "    output_transform=lambda x: None,\n",
    "    # fetch global epoch number from trainer\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "val_tensorboard_stats_handler.attach(evaluator)\n",
    "\n",
    "\n",
    "# add handler to record metrics to WandB at every validation epoch\n",
    "val_wandb_stats_handler = WandbStatsHandler(\n",
    "    # no need to plot loss value, so disable per iteration output\n",
    "    output_transform=lambda x: None,\n",
    "    # fetch global epoch number from trainer\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "val_wandb_stats_handler.attach(evaluator)\n",
    "\n",
    "\n",
    "checkpoint_handler = Checkpoint(\n",
    "    {\"model\": model, \"optimizer\": optimizer},\n",
    "    WandbModelCheckpointSaver(),\n",
    "    n_saved=1,\n",
    "    filename_prefix=\"best_checkpoint\",\n",
    "    score_name=metric_name,\n",
    "    global_step_transform=global_step_from_engine(trainer)\n",
    ")\n",
    "evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler)\n",
    "\n",
    "\n",
    "val_wandb_image_handler = WandBImageHandler(\n",
    "    batch_transform=lambda batch: (batch[0], batch[1]),\n",
    "    output_transform=lambda output: output[0],\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=ignite.engine.Events.EPOCH_COMPLETED,\n",
    "    handler=val_wandb_image_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 23:32:46,641 - INFO - Epoch: 1/1, Iter: 1/16 -- Loss: 0.6680 \n",
      "2023-04-20 23:32:47,344 - INFO - Epoch: 1/1, Iter: 2/16 -- Loss: 0.6614 \n",
      "2023-04-20 23:32:48,114 - INFO - Epoch: 1/1, Iter: 3/16 -- Loss: 0.6395 \n",
      "2023-04-20 23:32:48,897 - INFO - Epoch: 1/1, Iter: 4/16 -- Loss: 0.6536 \n",
      "2023-04-20 23:32:49,664 - INFO - Epoch: 1/1, Iter: 5/16 -- Loss: 0.6342 \n",
      "2023-04-20 23:32:50,465 - INFO - Epoch: 1/1, Iter: 6/16 -- Loss: 0.6387 \n",
      "2023-04-20 23:32:51,204 - INFO - Epoch: 1/1, Iter: 7/16 -- Loss: 0.5861 \n",
      "2023-04-20 23:32:51,992 - INFO - Epoch: 1/1, Iter: 8/16 -- Loss: 0.6171 \n",
      "2023-04-20 23:32:52,702 - INFO - Epoch: 1/1, Iter: 9/16 -- Loss: 0.6210 \n",
      "2023-04-20 23:32:53,748 - INFO - Epoch: 1/1, Iter: 10/16 -- Loss: 0.6245 \n",
      "2023-04-20 23:32:54,498 - INFO - Epoch: 1/1, Iter: 11/16 -- Loss: 0.6191 \n",
      "2023-04-20 23:32:55,312 - INFO - Epoch: 1/1, Iter: 12/16 -- Loss: 0.6280 \n",
      "2023-04-20 23:32:55,978 - INFO - Epoch: 1/1, Iter: 13/16 -- Loss: 0.5790 \n",
      "2023-04-20 23:32:56,719 - INFO - Epoch: 1/1, Iter: 14/16 -- Loss: 0.5648 \n",
      "2023-04-20 23:32:57,372 - INFO - Epoch: 1/1, Iter: 15/16 -- Loss: 0.6047 \n",
      "2023-04-20 23:32:58,030 - INFO - Epoch: 1/1, Iter: 16/16 -- Loss: 0.5804 \n",
      "2023-04-20 23:33:02,851 - INFO - Epoch[1] Metrics -- Mean_Dice: 0.5983 \n",
      "(1, 96, 96, 96)\n",
      "(1, 96, 96, 96)\n",
      "(2, 96, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "state = trainer.run(train_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▆▇▆▆▂▅▅▅▅▅▂▁▄▂</td></tr><tr><td>Mean_Dice</td><td>▁▁</td></tr><tr><td>global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.5804</td></tr><tr><td>Mean_Dice</td><td>0.59827</td></tr><tr><td>global_step</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-dust-72</strong> at: <a href='https://wandb.ai/geekyrakshit/monai-integration/runs/0re2ts61' target=\"_blank\">https://wandb.ai/geekyrakshit/monai-integration/runs/0re2ts61</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230420_232832-0re2ts61/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "shutil.rmtree(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
